{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 考虑将每一个项目（论文）表示为一个向量，考虑不同的feature对聚类结果对影响，消除时间对影响，比如发表越早的文章相应的star数，fork数等会多一些，那么考虑其增长速率：star/time\n",
    "\n",
    "# 供选择的feature有，paper方面，被引用数，paper中图片的数量，paper发表的时间，paper的作者，摘要，发表在什么地方，paper topic\n",
    "\n",
    "\n",
    "\n",
    "# github方面的可选择的feature有star, fork, watch, readme_size, time, code_frame, latest_issue_updated_time, open_issues_count, repo_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color=#0099ff face=\"黑体\">Step 1：</font>处理已经爬好的数据\n",
    "\n",
    "# <font color=#0099ff face=\"黑体\">Step 2：</font>构建数据集，特征向量定义为\n",
    "\n",
    "# $(repo\\_size,achieve,frame\\_feature,subscribe\\_count÷t,img\\_num,repo\\_kept\\_time,readme\\_size,open\\_issues\\_count÷t,forks\\_count÷t,star\\_counts÷t,cite\\_number÷t)$\n",
    "\n",
    "# <font color=#0099ff face=\"黑体\">Step 3：</font>使用KMeans聚类\n",
    "\n",
    "# <font color=#0099ff face=\"黑体\">Step 4：</font>使用PCA降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>paper_abstract</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_url_abs</th>\n",
       "      <th>paper_url_pdf</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>star_number</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tf]</td>\n",
       "      <td>We present a method for training a regress...</td>\n",
       "      <td>Unsupervised Training for 3D Morphable Model R...</td>\n",
       "      <td>https://arxiv.org/abs/1806.06098v1</td>\n",
       "      <td>https://arxiv.org/pdf/1806.06098v1.pdf</td>\n",
       "      <td>[https://github.com/google/tf_mesh_renderer]</td>\n",
       "      <td>[267]</td>\n",
       "      <td>[3d face reconstruction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>We introduce a new inference task - Visual...</td>\n",
       "      <td>Visual Entailment Task for Visually-Grounded L...</td>\n",
       "      <td>https://arxiv.org/abs/1811.10582v2</td>\n",
       "      <td>https://arxiv.org/pdf/1811.10582v2.pdf</td>\n",
       "      <td>[https://github.com/necla-ml/SNLI-VE]</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[natural language inference, question answerin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>Long Short-Term Memory (LSTM) is one of th...</td>\n",
       "      <td>Towards Binary-Valued Gates for Robust LSTM Tr...</td>\n",
       "      <td>https://arxiv.org/abs/1806.02988v1</td>\n",
       "      <td>https://arxiv.org/pdf/1806.02988v1.pdf</td>\n",
       "      <td>[https://github.com/zhuohan123/g2-lstm]</td>\n",
       "      <td>[56]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>The Vision-and-Language Navigation (VLN) t...</td>\n",
       "      <td>Self-Monitoring Navigation Agent via Auxiliary...</td>\n",
       "      <td>https://arxiv.org/abs/1901.03035v1</td>\n",
       "      <td>https://arxiv.org/pdf/1901.03035v1.pdf</td>\n",
       "      <td>[https://github.com/chihyaoma/selfmonitoring-a...</td>\n",
       "      <td>[73]</td>\n",
       "      <td>[natural language visual grounding, vision lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>We review the task of Sentence Pair Scorin...</td>\n",
       "      <td>Sentence Pair Scoring: Towards Unified Framewo...</td>\n",
       "      <td>https://arxiv.org/abs/1603.06127v4</td>\n",
       "      <td>https://arxiv.org/pdf/1603.06127v4.pdf</td>\n",
       "      <td>[https://github.com/brmson/dataset-sts]</td>\n",
       "      <td>[476]</td>\n",
       "      <td>[natural language inference, reading comprehen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>Evaluating open-domain dialogue systems is...</td>\n",
       "      <td>Evaluating Coherence in Dialogue Systems using...</td>\n",
       "      <td>https://arxiv.org/abs/1904.03371v1</td>\n",
       "      <td>https://arxiv.org/pdf/1904.03371v1.pdf</td>\n",
       "      <td>[https://github.com/nouhadziri/DialogEntailment]</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[torch, tf, tf, tf, tf]</td>\n",
       "      <td>Finding minimum distortion of adversarial ...</td>\n",
       "      <td>Efficient Neural Network Robustness Certificat...</td>\n",
       "      <td>https://arxiv.org/abs/1811.00866v1</td>\n",
       "      <td>https://arxiv.org/pdf/1811.00866v1.pdf</td>\n",
       "      <td>[https://github.com/huanzhang12/CROWN-IBP, htt...</td>\n",
       "      <td>[16, 10, 10, 10, 8]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[tf]</td>\n",
       "      <td>Capturing semantic relations between sente...</td>\n",
       "      <td>Grounded Textual Entailment</td>\n",
       "      <td>https://arxiv.org/abs/1806.05645v1</td>\n",
       "      <td>https://arxiv.org/pdf/1806.05645v1.pdf</td>\n",
       "      <td>[https://github.com/claudiogreco/coling18-gte]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[natural language inference]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[tf]</td>\n",
       "      <td>Automated Post-Editing (PE) is the task of...</td>\n",
       "      <td>Automatic Post-Editing of Machine Translation:...</td>\n",
       "      <td>https://www.aclweb.org/anthology/papers/D/D18/...</td>\n",
       "      <td>https://www.aclweb.org/anthology/D18-1341</td>\n",
       "      <td>[https://github.com/trangvu/ape-npi]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[automatic post editing, machine translation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[]</td>\n",
       "      <td>Many practical applications of machine lea...</td>\n",
       "      <td>Meta-Learning Acquisition Functions for Bayesi...</td>\n",
       "      <td>https://arxiv.org/abs/1904.02642v3</td>\n",
       "      <td>https://arxiv.org/pdf/1904.02642v3.pdf</td>\n",
       "      <td>[https://github.com/boschresearch/MetaBO]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[meta learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[]</td>\n",
       "      <td>In many applications of black-box optimiza...</td>\n",
       "      <td>The Parallel Knowledge Gradient Method for Bat...</td>\n",
       "      <td>https://arxiv.org/abs/1606.04414v4</td>\n",
       "      <td>https://arxiv.org/pdf/1606.04414v4.pdf</td>\n",
       "      <td>[https://github.com/wujian16/qKG, https://gith...</td>\n",
       "      <td>[135, 135]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[]</td>\n",
       "      <td>Traditional place categorization approache...</td>\n",
       "      <td>Robust Place Categorization with Deep Domain G...</td>\n",
       "      <td>https://arxiv.org/abs/1805.12048v1</td>\n",
       "      <td>https://arxiv.org/pdf/1805.12048v1.pdf</td>\n",
       "      <td>[https://github.com/mancinimassimiliano/caffe]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[domain adaptation, domain generalization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[tf, torch]</td>\n",
       "      <td>Deep learning is formulated as a discrete-...</td>\n",
       "      <td>An Optimal Control Approach to Deep Learning a...</td>\n",
       "      <td>https://arxiv.org/abs/1803.01299v2</td>\n",
       "      <td>https://arxiv.org/pdf/1803.01299v2.pdf</td>\n",
       "      <td>[https://github.com/LiQianxiao/discrete-MSA, h...</td>\n",
       "      <td>[14, 0]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[]</td>\n",
       "      <td>The success of machine learning in a broad...</td>\n",
       "      <td>Efficient and Robust Automated Machine Learning</td>\n",
       "      <td>http://papers.nips.cc/paper/5872-efficient-and...</td>\n",
       "      <td>http://papers.nips.cc/paper/5872-efficient-and...</td>\n",
       "      <td>[https://github.com/automl/auto-sklearn]</td>\n",
       "      <td>[3752]</td>\n",
       "      <td>[automl, hyperparameter optimization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[]</td>\n",
       "      <td>This paper presents a method of designing ...</td>\n",
       "      <td>Connecting Distant Entities with Induction thr...</td>\n",
       "      <td>https://arxiv.org/abs/1805.10414v1</td>\n",
       "      <td>https://arxiv.org/pdf/1805.10414v1.pdf</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[named entity recognition ner]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[]</td>\n",
       "      <td>Machine learning algorithms frequently req...</td>\n",
       "      <td>Practical Bayesian Optimization of Machine Lea...</td>\n",
       "      <td>https://arxiv.org/abs/1206.2944v2</td>\n",
       "      <td>https://arxiv.org/pdf/1206.2944v2.pdf</td>\n",
       "      <td>[https://github.com/JasperSnoek/spearmint, htt...</td>\n",
       "      <td>[1265, 1262, 0]</td>\n",
       "      <td>[hyperparameter optimization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[]</td>\n",
       "      <td>In this paper, we propose the Interactive ...</td>\n",
       "      <td>Interactive Text2Pickup Network for Natural La...</td>\n",
       "      <td>https://arxiv.org/abs/1805.10799v1</td>\n",
       "      <td>https://arxiv.org/pdf/1805.10799v1.pdf</td>\n",
       "      <td>[https://github.com/hiddenmaze/InteractivePickup]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[torch, torch]</td>\n",
       "      <td>Hamiltonian Monte Carlo (HMC) sampling met...</td>\n",
       "      <td>Stochastic Gradient Hamiltonian Monte Carlo</td>\n",
       "      <td>https://arxiv.org/abs/1402.4102v2</td>\n",
       "      <td>https://arxiv.org/pdf/1402.4102v2.pdf</td>\n",
       "      <td>[https://github.com/hsvgbkhgbv/TACTHMC, https:...</td>\n",
       "      <td>[4, 4, 0]</td>\n",
       "      <td>[efficient exploration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[]</td>\n",
       "      <td>Ordinal Regression (OR) aims to model the ...</td>\n",
       "      <td>Incremental Sparse Bayesian Ordinal Regression</td>\n",
       "      <td>https://arxiv.org/abs/1806.06553v1</td>\n",
       "      <td>https://arxiv.org/pdf/1806.06553v1.pdf</td>\n",
       "      <td>[https://github.com/chang-li/SBOR]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[multi label learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[]</td>\n",
       "      <td>As machine learning is applied more widely...</td>\n",
       "      <td>The Machine Learning Bazaar: Harnessing the ML...</td>\n",
       "      <td>https://arxiv.org/abs/1905.08942v2</td>\n",
       "      <td>https://arxiv.org/pdf/1905.08942v2.pdf</td>\n",
       "      <td>[https://github.com/HDI-Project/AutoBazaar]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[anomaly detection, automl, graph matching]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[]</td>\n",
       "      <td>We propose a Bayesian optimization algorit...</td>\n",
       "      <td>Bayesian Optimization with Expensive Integrands</td>\n",
       "      <td>https://arxiv.org/abs/1803.08661v1</td>\n",
       "      <td>https://arxiv.org/pdf/1803.08661v1.pdf</td>\n",
       "      <td>[https://github.com/toscanosaul/bayesian_quadr...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[]</td>\n",
       "      <td>In Multi-Goal Reinforcement Learning, an a...</td>\n",
       "      <td>Maximum Entropy-Regularized Multi-Goal Reinfor...</td>\n",
       "      <td>https://arxiv.org/abs/1905.08786v2</td>\n",
       "      <td>https://arxiv.org/pdf/1905.08786v2.pdf</td>\n",
       "      <td>[https://github.com/ruizhaogit/mep]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[multi goal reinforcement learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[tf]</td>\n",
       "      <td>Bayesian Optimisation (BO) refers to a cla...</td>\n",
       "      <td>Neural Architecture Search with Bayesian Optim...</td>\n",
       "      <td>https://arxiv.org/abs/1802.07191v3</td>\n",
       "      <td>https://arxiv.org/pdf/1802.07191v3.pdf</td>\n",
       "      <td>[https://github.com/kirthevasank/nasbot]</td>\n",
       "      <td>[92]</td>\n",
       "      <td>[bayesian optimisation, model selection, archi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[]</td>\n",
       "      <td>Bayesian optimization is an approach to op...</td>\n",
       "      <td>A Tutorial on Bayesian Optimization</td>\n",
       "      <td>https://arxiv.org/abs/1807.02811v1</td>\n",
       "      <td>https://arxiv.org/pdf/1807.02811v1.pdf</td>\n",
       "      <td>[https://github.com/wujian16/qKG, https://gith...</td>\n",
       "      <td>[135, 135, 0]</td>\n",
       "      <td>[hyperparameter optimization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[]</td>\n",
       "      <td>We propose minimum regret search (MRS), a ...</td>\n",
       "      <td>Minimum Regret Search for Single- and Multi-Ta...</td>\n",
       "      <td>https://arxiv.org/abs/1602.01064v3</td>\n",
       "      <td>https://arxiv.org/pdf/1602.01064v3.pdf</td>\n",
       "      <td>[https://github.com/jmetzen/bayesian_optimizat...</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[]</td>\n",
       "      <td>Bayesian optimization has proven to be a h...</td>\n",
       "      <td>Input Warping for Bayesian Optimization of Non...</td>\n",
       "      <td>https://arxiv.org/abs/1402.0929v3</td>\n",
       "      <td>https://arxiv.org/pdf/1402.0929v3.pdf</td>\n",
       "      <td>[https://github.com/HIPS/Spearmint]</td>\n",
       "      <td>[1262]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>We propose a new sampling method, the ther...</td>\n",
       "      <td>Thermostat-assisted continuously-tempered Hami...</td>\n",
       "      <td>https://arxiv.org/abs/1711.11511v5</td>\n",
       "      <td>https://arxiv.org/pdf/1711.11511v5.pdf</td>\n",
       "      <td>[https://github.com/hsvgbkhgbv/TACTHMC]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[tf]</td>\n",
       "      <td>We propose `Hide-and-Seek', a weakly-super...</td>\n",
       "      <td>Hide-and-Seek: Forcing a Network to be Meticul...</td>\n",
       "      <td>https://arxiv.org/abs/1704.04232v2</td>\n",
       "      <td>https://arxiv.org/pdf/1704.04232v2.pdf</td>\n",
       "      <td>[https://github.com/zhengshou/AutoLoc, https:/...</td>\n",
       "      <td>[52, 4]</td>\n",
       "      <td>[action localization, object localization, wea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[]</td>\n",
       "      <td>In this work we aim to predict the driver'...</td>\n",
       "      <td>Predicting the Driver's Focus of Attention: th...</td>\n",
       "      <td>https://arxiv.org/abs/1705.03854v3</td>\n",
       "      <td>https://arxiv.org/pdf/1705.03854v3.pdf</td>\n",
       "      <td>[https://github.com/ndrplz/dreyeve]</td>\n",
       "      <td>[56]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[tf]</td>\n",
       "      <td>Our understanding of reinforcement learnin...</td>\n",
       "      <td>TD or not TD: Analyzing the Role of Temporal D...</td>\n",
       "      <td>https://arxiv.org/abs/1806.01175v1</td>\n",
       "      <td>https://arxiv.org/pdf/1806.01175v1.pdf</td>\n",
       "      <td>[https://github.com/lmb-freiburg/td-or-not-td]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14166</th>\n",
       "      <td>[tf]</td>\n",
       "      <td>One popular generative model that has high...</td>\n",
       "      <td>A Study into the similarity in generator and d...</td>\n",
       "      <td>https://arxiv.org/abs/1802.07401v1</td>\n",
       "      <td>https://arxiv.org/pdf/1802.07401v1.pdf</td>\n",
       "      <td>[https://github.com/arjun23496/Shared-WGAN]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14167</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>We formalize a new modular variant of curr...</td>\n",
       "      <td>Phrase-Indexed Question Answering: A New Chall...</td>\n",
       "      <td>https://arxiv.org/abs/1804.07726v2</td>\n",
       "      <td>https://arxiv.org/pdf/1804.07726v2.pdf</td>\n",
       "      <td>[https://github.com/ethonyLight/piqa_bert]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[question answering, reading comprehension]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14168</th>\n",
       "      <td>[]</td>\n",
       "      <td>This paper studies recommender systems wit...</td>\n",
       "      <td>Explainable Knowledge Graph-based Recommendati...</td>\n",
       "      <td>https://arxiv.org/abs/1906.09506v1</td>\n",
       "      <td>https://arxiv.org/pdf/1906.09506v1.pdf</td>\n",
       "      <td>[https://github.com/DeepGraphLearning/Recommen...</td>\n",
       "      <td>[187]</td>\n",
       "      <td>[knowledge graphs, policy gradient methods, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14169</th>\n",
       "      <td>[]</td>\n",
       "      <td>The Centers for Disease Control and Preven...</td>\n",
       "      <td>A Comparison of Machine Learning Algorithms fo...</td>\n",
       "      <td>https://arxiv.org/abs/1804.06223v3</td>\n",
       "      <td>https://arxiv.org/pdf/1804.06223v3.pdf</td>\n",
       "      <td>[https://github.com/scotthlee/autism_classific...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[document classification]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14170</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>Unlike mainstream languages (such as Engli...</td>\n",
       "      <td>Evaluating Language Model Finetuning Technique...</td>\n",
       "      <td>https://arxiv.org/abs/1907.00409v1</td>\n",
       "      <td>https://arxiv.org/pdf/1907.00409v1.pdf</td>\n",
       "      <td>[https://github.com/jcblaisecruz02/Tagalog-BERT]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[language modelling]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14171</th>\n",
       "      <td>[]</td>\n",
       "      <td>In this work, we introduce three generic p...</td>\n",
       "      <td>Going Deeper with Point Networks</td>\n",
       "      <td>https://arxiv.org/abs/1907.00960v1</td>\n",
       "      <td>https://arxiv.org/pdf/1907.00960v1.pdf</td>\n",
       "      <td>[https://github.com/erictuanle/GoingDeeperwPoi...</td>\n",
       "      <td>[16]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14172</th>\n",
       "      <td>[]</td>\n",
       "      <td>Euclidean embeddings of data are fundament...</td>\n",
       "      <td>Learning Embeddings into Entropic Wasserstein ...</td>\n",
       "      <td>https://arxiv.org/abs/1905.03329v1</td>\n",
       "      <td>https://arxiv.org/pdf/1905.03329v1.pdf</td>\n",
       "      <td>[https://github.com/gabsens/Learning-Embedding...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[dimensionality reduction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14173</th>\n",
       "      <td>[]</td>\n",
       "      <td>Our goal is to accurately and efficiently ...</td>\n",
       "      <td>Learning Reward Functions by Integrating Human...</td>\n",
       "      <td>https://arxiv.org/abs/1906.08928v1</td>\n",
       "      <td>https://arxiv.org/pdf/1906.08928v1.pdf</td>\n",
       "      <td>[https://github.com/malayandi/DemPrefCode]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14174</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>Current deep neural network based approach...</td>\n",
       "      <td>ADN: Artifact Disentanglement Network for Unsu...</td>\n",
       "      <td>https://arxiv.org/abs/1908.01104v3</td>\n",
       "      <td>https://arxiv.org/pdf/1908.01104v3.pdf</td>\n",
       "      <td>[https://github.com/liaohaofu/adn]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[image to image translation, metal artifact re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14175</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>We study the problem of learning represent...</td>\n",
       "      <td>Connectivity-Optimized Representation Learning...</td>\n",
       "      <td>https://arxiv.org/abs/1906.09003v1</td>\n",
       "      <td>https://arxiv.org/pdf/1906.09003v1.pdf</td>\n",
       "      <td>[https://github.com/c-hofer/COREL_icml2019]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[representation learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14176</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>Current deep neural network based approach...</td>\n",
       "      <td>Artifact Disentanglement Network for Unsupervi...</td>\n",
       "      <td>https://arxiv.org/abs/1906.01806v4</td>\n",
       "      <td>https://arxiv.org/pdf/1906.01806v4.pdf</td>\n",
       "      <td>[https://github.com/liaohaofu/adn]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[image to image translation, metal artifact re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14177</th>\n",
       "      <td>[]</td>\n",
       "      <td>Big data analytics is gaining massive mome...</td>\n",
       "      <td>Rafiki: Machine Learning as an Analytics Servi...</td>\n",
       "      <td>https://arxiv.org/abs/1804.06087v1</td>\n",
       "      <td>https://arxiv.org/pdf/1804.06087v1.pdf</td>\n",
       "      <td>[https://github.com/nginyc/rafiki]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>[automl, hyperparameter optimization, image cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14178</th>\n",
       "      <td>[]</td>\n",
       "      <td>We study two problems in high-dimensional ...</td>\n",
       "      <td>Quantum Entropy Scoring for Fast Robust Mean E...</td>\n",
       "      <td>https://arxiv.org/abs/1906.11366v1</td>\n",
       "      <td>https://arxiv.org/pdf/1906.11366v1.pdf</td>\n",
       "      <td>[https://github.com/twistedcubic/que-outlier-d...</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[outlier detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14179</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>Text-based question answering (TBQA) has b...</td>\n",
       "      <td>Dynamically Fused Graph Network for Multi-hop ...</td>\n",
       "      <td>https://arxiv.org/abs/1905.06933v3</td>\n",
       "      <td>https://arxiv.org/pdf/1905.06933v3.pdf</td>\n",
       "      <td>[https://github.com/woshiyyya/DFGN-pytorch]</td>\n",
       "      <td>[55]</td>\n",
       "      <td>[question answering]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14180</th>\n",
       "      <td>[]</td>\n",
       "      <td>Temporal segmentation of untrimmed videos ...</td>\n",
       "      <td>Enhancing temporal segmentation by nonlocal se...</td>\n",
       "      <td>https://arxiv.org/abs/1906.11335v1</td>\n",
       "      <td>https://arxiv.org/pdf/1906.11335v1.pdf</td>\n",
       "      <td>[https://github.com/mdimiccoli/Nonlocal-self-s...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14181</th>\n",
       "      <td>[]</td>\n",
       "      <td>Facial landmark detection is an important ...</td>\n",
       "      <td>Combining Data-driven and Model-driven Methods...</td>\n",
       "      <td>https://arxiv.org/abs/1611.10152v2</td>\n",
       "      <td>https://arxiv.org/pdf/1611.10152v2.pdf</td>\n",
       "      <td>[https://github.com/HongwenZhang/ECT-FaceAlign...</td>\n",
       "      <td>[22]</td>\n",
       "      <td>[facial landmark detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14182</th>\n",
       "      <td>[]</td>\n",
       "      <td>Large-scale annotation of image segmentati...</td>\n",
       "      <td>FreeLabel: A Publicly Available Annotation Too...</td>\n",
       "      <td>https://arxiv.org/abs/1902.06806v2</td>\n",
       "      <td>https://arxiv.org/pdf/1902.06806v2.pdf</td>\n",
       "      <td>[https://github.com/philadias/freelabel]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[semantic segmentation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14183</th>\n",
       "      <td>[]</td>\n",
       "      <td>Lane detection is extremely important for ...</td>\n",
       "      <td>Lane Detection and Classification using Cascad...</td>\n",
       "      <td>https://arxiv.org/abs/1907.01294v2</td>\n",
       "      <td>https://arxiv.org/pdf/1907.01294v2.pdf</td>\n",
       "      <td>[https://github.com/fabvio/Cascade-LD, https:/...</td>\n",
       "      <td>[7, 4]</td>\n",
       "      <td>[autonomous vehicles, lane detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14184</th>\n",
       "      <td>[tf]</td>\n",
       "      <td>In this paper we address the problem of ge...</td>\n",
       "      <td>Deformable GANs for Pose-based Human Image Gen...</td>\n",
       "      <td>https://arxiv.org/abs/1801.00055v2</td>\n",
       "      <td>https://arxiv.org/pdf/1801.00055v2.pdf</td>\n",
       "      <td>[https://github.com/AliaksandrSiarohin/pose-gan]</td>\n",
       "      <td>[193]</td>\n",
       "      <td>[gesture to gesture translation, image generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14185</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>The phenomenon of Adversarial Examples is ...</td>\n",
       "      <td>Characterizing and evaluating adversarial exam...</td>\n",
       "      <td>https://arxiv.org/abs/1901.03398v1</td>\n",
       "      <td>https://arxiv.org/pdf/1901.03398v1.pdf</td>\n",
       "      <td>[https://github.com/luizgh/sigver]</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[object recognition]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14186</th>\n",
       "      <td>[tf]</td>\n",
       "      <td>Facial makeup transfer is a widely-used te...</td>\n",
       "      <td>Disentangled Makeup Transfer with Generative A...</td>\n",
       "      <td>https://arxiv.org/abs/1907.01144v1</td>\n",
       "      <td>https://arxiv.org/pdf/1907.01144v1.pdf</td>\n",
       "      <td>[https://github.com/Honlan/DMT]</td>\n",
       "      <td>[11]</td>\n",
       "      <td>[facial makeup transfer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14187</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>Grammatical error correction can be viewed...</td>\n",
       "      <td>A Neural Grammatical Error Correction System B...</td>\n",
       "      <td>https://arxiv.org/abs/1907.01256v1</td>\n",
       "      <td>https://arxiv.org/pdf/1907.01256v1.pdf</td>\n",
       "      <td>[https://github.com/kakaobrain/helo_word]</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[grammatical error correction, transfer learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14188</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>Most malicious photo manipulations are cre...</td>\n",
       "      <td>Detecting Photoshopped Faces by Scripting Phot...</td>\n",
       "      <td>https://arxiv.org/abs/1906.05856v1</td>\n",
       "      <td>https://arxiv.org/pdf/1906.05856v1.pdf</td>\n",
       "      <td>[https://github.com/PeterWang512/FALdetector]</td>\n",
       "      <td>[428]</td>\n",
       "      <td>[image manipulation detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14189</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>We explore the problem of real-time stereo...</td>\n",
       "      <td>Hierarchical Deep Stereo Matching on High-Reso...</td>\n",
       "      <td>http://openaccess.thecvf.com/content_CVPR_2019...</td>\n",
       "      <td>http://openaccess.thecvf.com/content_CVPR_2019...</td>\n",
       "      <td>[https://github.com/gengshan-y/high-res-stereo]</td>\n",
       "      <td>[31]</td>\n",
       "      <td>[autonomous driving, stereo matching]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14190</th>\n",
       "      <td>[]</td>\n",
       "      <td>Despite the recent success of scene text d...</td>\n",
       "      <td>TedEval: A Fair Evaluation Metric for Scene Te...</td>\n",
       "      <td>https://arxiv.org/abs/1907.01227v1</td>\n",
       "      <td>https://arxiv.org/pdf/1907.01227v1.pdf</td>\n",
       "      <td>[https://github.com/clovaai/TedEval]</td>\n",
       "      <td>[73]</td>\n",
       "      <td>[scene text detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14191</th>\n",
       "      <td>[tf]</td>\n",
       "      <td>Existing objective evaluation metrics for ...</td>\n",
       "      <td>MOSNet: Deep Learning based Objective Assessme...</td>\n",
       "      <td>https://arxiv.org/abs/1904.08352v2</td>\n",
       "      <td>https://arxiv.org/pdf/1904.08352v2.pdf</td>\n",
       "      <td>[https://github.com/lochenchou/MOSNet]</td>\n",
       "      <td>[11]</td>\n",
       "      <td>[voice conversion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14192</th>\n",
       "      <td>[]</td>\n",
       "      <td>Humans can ground natural language command...</td>\n",
       "      <td>Accurately and Efficiently Interpreting Human-...</td>\n",
       "      <td>https://arxiv.org/abs/1704.06616v2</td>\n",
       "      <td>https://arxiv.org/pdf/1704.06616v2.pdf</td>\n",
       "      <td>[https://github.com/h2r/GLAMDP]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14193</th>\n",
       "      <td>[]</td>\n",
       "      <td>Rule-based systems play a critical role in...</td>\n",
       "      <td>Rule Applicability on RDF Triplestore Schemas</td>\n",
       "      <td>https://arxiv.org/abs/1907.01627v1</td>\n",
       "      <td>https://arxiv.org/pdf/1907.01627v1.pdf</td>\n",
       "      <td>[https://github.com/paolo7/ap2]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14194</th>\n",
       "      <td>[]</td>\n",
       "      <td>In unsupervised domain adaptation, existin...</td>\n",
       "      <td>Learning Smooth Representation for Unsupervise...</td>\n",
       "      <td>https://arxiv.org/abs/1905.10748v2</td>\n",
       "      <td>https://arxiv.org/pdf/1905.10748v2.pdf</td>\n",
       "      <td>[https://github.com/CuthbertCai/SRDA]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[domain adaptation, unsupervised domain adapta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14195</th>\n",
       "      <td>[torch]</td>\n",
       "      <td>Automatic prostate segmentation in transre...</td>\n",
       "      <td>Deep Attentive Features for Prostate Segmentat...</td>\n",
       "      <td>https://arxiv.org/abs/1907.01743v1</td>\n",
       "      <td>https://arxiv.org/pdf/1907.01743v1.pdf</td>\n",
       "      <td>[https://github.com/wulalago/DAF3D]</td>\n",
       "      <td>[14]</td>\n",
       "      <td>[medical image segmentation, semantic segmenta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14196 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         frame  \\\n",
       "0                         [tf]   \n",
       "1                           []   \n",
       "2                      [torch]   \n",
       "3                      [torch]   \n",
       "4                           []   \n",
       "5                      [torch]   \n",
       "6      [torch, tf, tf, tf, tf]   \n",
       "7                         [tf]   \n",
       "8                         [tf]   \n",
       "9                           []   \n",
       "10                          []   \n",
       "11                          []   \n",
       "12                 [tf, torch]   \n",
       "13                          []   \n",
       "14                          []   \n",
       "15                          []   \n",
       "16                          []   \n",
       "17              [torch, torch]   \n",
       "18                          []   \n",
       "19                          []   \n",
       "20                          []   \n",
       "21                          []   \n",
       "22                        [tf]   \n",
       "23                          []   \n",
       "24                          []   \n",
       "25                          []   \n",
       "26                     [torch]   \n",
       "27                        [tf]   \n",
       "28                          []   \n",
       "29                        [tf]   \n",
       "...                        ...   \n",
       "14166                     [tf]   \n",
       "14167                  [torch]   \n",
       "14168                       []   \n",
       "14169                       []   \n",
       "14170                  [torch]   \n",
       "14171                       []   \n",
       "14172                       []   \n",
       "14173                       []   \n",
       "14174                  [torch]   \n",
       "14175                  [torch]   \n",
       "14176                  [torch]   \n",
       "14177                       []   \n",
       "14178                       []   \n",
       "14179                  [torch]   \n",
       "14180                       []   \n",
       "14181                       []   \n",
       "14182                       []   \n",
       "14183                       []   \n",
       "14184                     [tf]   \n",
       "14185                  [torch]   \n",
       "14186                     [tf]   \n",
       "14187                  [torch]   \n",
       "14188                  [torch]   \n",
       "14189                  [torch]   \n",
       "14190                       []   \n",
       "14191                     [tf]   \n",
       "14192                       []   \n",
       "14193                       []   \n",
       "14194                       []   \n",
       "14195                  [torch]   \n",
       "\n",
       "                                          paper_abstract  \\\n",
       "0          We present a method for training a regress...   \n",
       "1          We introduce a new inference task - Visual...   \n",
       "2          Long Short-Term Memory (LSTM) is one of th...   \n",
       "3          The Vision-and-Language Navigation (VLN) t...   \n",
       "4          We review the task of Sentence Pair Scorin...   \n",
       "5          Evaluating open-domain dialogue systems is...   \n",
       "6          Finding minimum distortion of adversarial ...   \n",
       "7          Capturing semantic relations between sente...   \n",
       "8          Automated Post-Editing (PE) is the task of...   \n",
       "9          Many practical applications of machine lea...   \n",
       "10         In many applications of black-box optimiza...   \n",
       "11         Traditional place categorization approache...   \n",
       "12         Deep learning is formulated as a discrete-...   \n",
       "13         The success of machine learning in a broad...   \n",
       "14         This paper presents a method of designing ...   \n",
       "15         Machine learning algorithms frequently req...   \n",
       "16         In this paper, we propose the Interactive ...   \n",
       "17         Hamiltonian Monte Carlo (HMC) sampling met...   \n",
       "18         Ordinal Regression (OR) aims to model the ...   \n",
       "19         As machine learning is applied more widely...   \n",
       "20         We propose a Bayesian optimization algorit...   \n",
       "21         In Multi-Goal Reinforcement Learning, an a...   \n",
       "22         Bayesian Optimisation (BO) refers to a cla...   \n",
       "23         Bayesian optimization is an approach to op...   \n",
       "24         We propose minimum regret search (MRS), a ...   \n",
       "25         Bayesian optimization has proven to be a h...   \n",
       "26         We propose a new sampling method, the ther...   \n",
       "27         We propose `Hide-and-Seek', a weakly-super...   \n",
       "28         In this work we aim to predict the driver'...   \n",
       "29         Our understanding of reinforcement learnin...   \n",
       "...                                                  ...   \n",
       "14166      One popular generative model that has high...   \n",
       "14167      We formalize a new modular variant of curr...   \n",
       "14168      This paper studies recommender systems wit...   \n",
       "14169      The Centers for Disease Control and Preven...   \n",
       "14170      Unlike mainstream languages (such as Engli...   \n",
       "14171      In this work, we introduce three generic p...   \n",
       "14172      Euclidean embeddings of data are fundament...   \n",
       "14173      Our goal is to accurately and efficiently ...   \n",
       "14174      Current deep neural network based approach...   \n",
       "14175      We study the problem of learning represent...   \n",
       "14176      Current deep neural network based approach...   \n",
       "14177      Big data analytics is gaining massive mome...   \n",
       "14178      We study two problems in high-dimensional ...   \n",
       "14179      Text-based question answering (TBQA) has b...   \n",
       "14180      Temporal segmentation of untrimmed videos ...   \n",
       "14181      Facial landmark detection is an important ...   \n",
       "14182      Large-scale annotation of image segmentati...   \n",
       "14183      Lane detection is extremely important for ...   \n",
       "14184      In this paper we address the problem of ge...   \n",
       "14185      The phenomenon of Adversarial Examples is ...   \n",
       "14186      Facial makeup transfer is a widely-used te...   \n",
       "14187      Grammatical error correction can be viewed...   \n",
       "14188      Most malicious photo manipulations are cre...   \n",
       "14189      We explore the problem of real-time stereo...   \n",
       "14190      Despite the recent success of scene text d...   \n",
       "14191      Existing objective evaluation metrics for ...   \n",
       "14192      Humans can ground natural language command...   \n",
       "14193      Rule-based systems play a critical role in...   \n",
       "14194      In unsupervised domain adaptation, existin...   \n",
       "14195      Automatic prostate segmentation in transre...   \n",
       "\n",
       "                                             paper_title  \\\n",
       "0      Unsupervised Training for 3D Morphable Model R...   \n",
       "1      Visual Entailment Task for Visually-Grounded L...   \n",
       "2      Towards Binary-Valued Gates for Robust LSTM Tr...   \n",
       "3      Self-Monitoring Navigation Agent via Auxiliary...   \n",
       "4      Sentence Pair Scoring: Towards Unified Framewo...   \n",
       "5      Evaluating Coherence in Dialogue Systems using...   \n",
       "6      Efficient Neural Network Robustness Certificat...   \n",
       "7                            Grounded Textual Entailment   \n",
       "8      Automatic Post-Editing of Machine Translation:...   \n",
       "9      Meta-Learning Acquisition Functions for Bayesi...   \n",
       "10     The Parallel Knowledge Gradient Method for Bat...   \n",
       "11     Robust Place Categorization with Deep Domain G...   \n",
       "12     An Optimal Control Approach to Deep Learning a...   \n",
       "13       Efficient and Robust Automated Machine Learning   \n",
       "14     Connecting Distant Entities with Induction thr...   \n",
       "15     Practical Bayesian Optimization of Machine Lea...   \n",
       "16     Interactive Text2Pickup Network for Natural La...   \n",
       "17           Stochastic Gradient Hamiltonian Monte Carlo   \n",
       "18        Incremental Sparse Bayesian Ordinal Regression   \n",
       "19     The Machine Learning Bazaar: Harnessing the ML...   \n",
       "20       Bayesian Optimization with Expensive Integrands   \n",
       "21     Maximum Entropy-Regularized Multi-Goal Reinfor...   \n",
       "22     Neural Architecture Search with Bayesian Optim...   \n",
       "23                   A Tutorial on Bayesian Optimization   \n",
       "24     Minimum Regret Search for Single- and Multi-Ta...   \n",
       "25     Input Warping for Bayesian Optimization of Non...   \n",
       "26     Thermostat-assisted continuously-tempered Hami...   \n",
       "27     Hide-and-Seek: Forcing a Network to be Meticul...   \n",
       "28     Predicting the Driver's Focus of Attention: th...   \n",
       "29     TD or not TD: Analyzing the Role of Temporal D...   \n",
       "...                                                  ...   \n",
       "14166  A Study into the similarity in generator and d...   \n",
       "14167  Phrase-Indexed Question Answering: A New Chall...   \n",
       "14168  Explainable Knowledge Graph-based Recommendati...   \n",
       "14169  A Comparison of Machine Learning Algorithms fo...   \n",
       "14170  Evaluating Language Model Finetuning Technique...   \n",
       "14171                   Going Deeper with Point Networks   \n",
       "14172  Learning Embeddings into Entropic Wasserstein ...   \n",
       "14173  Learning Reward Functions by Integrating Human...   \n",
       "14174  ADN: Artifact Disentanglement Network for Unsu...   \n",
       "14175  Connectivity-Optimized Representation Learning...   \n",
       "14176  Artifact Disentanglement Network for Unsupervi...   \n",
       "14177  Rafiki: Machine Learning as an Analytics Servi...   \n",
       "14178  Quantum Entropy Scoring for Fast Robust Mean E...   \n",
       "14179  Dynamically Fused Graph Network for Multi-hop ...   \n",
       "14180  Enhancing temporal segmentation by nonlocal se...   \n",
       "14181  Combining Data-driven and Model-driven Methods...   \n",
       "14182  FreeLabel: A Publicly Available Annotation Too...   \n",
       "14183  Lane Detection and Classification using Cascad...   \n",
       "14184  Deformable GANs for Pose-based Human Image Gen...   \n",
       "14185  Characterizing and evaluating adversarial exam...   \n",
       "14186  Disentangled Makeup Transfer with Generative A...   \n",
       "14187  A Neural Grammatical Error Correction System B...   \n",
       "14188  Detecting Photoshopped Faces by Scripting Phot...   \n",
       "14189  Hierarchical Deep Stereo Matching on High-Reso...   \n",
       "14190  TedEval: A Fair Evaluation Metric for Scene Te...   \n",
       "14191  MOSNet: Deep Learning based Objective Assessme...   \n",
       "14192  Accurately and Efficiently Interpreting Human-...   \n",
       "14193      Rule Applicability on RDF Triplestore Schemas   \n",
       "14194  Learning Smooth Representation for Unsupervise...   \n",
       "14195  Deep Attentive Features for Prostate Segmentat...   \n",
       "\n",
       "                                           paper_url_abs  \\\n",
       "0                     https://arxiv.org/abs/1806.06098v1   \n",
       "1                     https://arxiv.org/abs/1811.10582v2   \n",
       "2                     https://arxiv.org/abs/1806.02988v1   \n",
       "3                     https://arxiv.org/abs/1901.03035v1   \n",
       "4                     https://arxiv.org/abs/1603.06127v4   \n",
       "5                     https://arxiv.org/abs/1904.03371v1   \n",
       "6                     https://arxiv.org/abs/1811.00866v1   \n",
       "7                     https://arxiv.org/abs/1806.05645v1   \n",
       "8      https://www.aclweb.org/anthology/papers/D/D18/...   \n",
       "9                     https://arxiv.org/abs/1904.02642v3   \n",
       "10                    https://arxiv.org/abs/1606.04414v4   \n",
       "11                    https://arxiv.org/abs/1805.12048v1   \n",
       "12                    https://arxiv.org/abs/1803.01299v2   \n",
       "13     http://papers.nips.cc/paper/5872-efficient-and...   \n",
       "14                    https://arxiv.org/abs/1805.10414v1   \n",
       "15                     https://arxiv.org/abs/1206.2944v2   \n",
       "16                    https://arxiv.org/abs/1805.10799v1   \n",
       "17                     https://arxiv.org/abs/1402.4102v2   \n",
       "18                    https://arxiv.org/abs/1806.06553v1   \n",
       "19                    https://arxiv.org/abs/1905.08942v2   \n",
       "20                    https://arxiv.org/abs/1803.08661v1   \n",
       "21                    https://arxiv.org/abs/1905.08786v2   \n",
       "22                    https://arxiv.org/abs/1802.07191v3   \n",
       "23                    https://arxiv.org/abs/1807.02811v1   \n",
       "24                    https://arxiv.org/abs/1602.01064v3   \n",
       "25                     https://arxiv.org/abs/1402.0929v3   \n",
       "26                    https://arxiv.org/abs/1711.11511v5   \n",
       "27                    https://arxiv.org/abs/1704.04232v2   \n",
       "28                    https://arxiv.org/abs/1705.03854v3   \n",
       "29                    https://arxiv.org/abs/1806.01175v1   \n",
       "...                                                  ...   \n",
       "14166                 https://arxiv.org/abs/1802.07401v1   \n",
       "14167                 https://arxiv.org/abs/1804.07726v2   \n",
       "14168                 https://arxiv.org/abs/1906.09506v1   \n",
       "14169                 https://arxiv.org/abs/1804.06223v3   \n",
       "14170                 https://arxiv.org/abs/1907.00409v1   \n",
       "14171                 https://arxiv.org/abs/1907.00960v1   \n",
       "14172                 https://arxiv.org/abs/1905.03329v1   \n",
       "14173                 https://arxiv.org/abs/1906.08928v1   \n",
       "14174                 https://arxiv.org/abs/1908.01104v3   \n",
       "14175                 https://arxiv.org/abs/1906.09003v1   \n",
       "14176                 https://arxiv.org/abs/1906.01806v4   \n",
       "14177                 https://arxiv.org/abs/1804.06087v1   \n",
       "14178                 https://arxiv.org/abs/1906.11366v1   \n",
       "14179                 https://arxiv.org/abs/1905.06933v3   \n",
       "14180                 https://arxiv.org/abs/1906.11335v1   \n",
       "14181                 https://arxiv.org/abs/1611.10152v2   \n",
       "14182                 https://arxiv.org/abs/1902.06806v2   \n",
       "14183                 https://arxiv.org/abs/1907.01294v2   \n",
       "14184                 https://arxiv.org/abs/1801.00055v2   \n",
       "14185                 https://arxiv.org/abs/1901.03398v1   \n",
       "14186                 https://arxiv.org/abs/1907.01144v1   \n",
       "14187                 https://arxiv.org/abs/1907.01256v1   \n",
       "14188                 https://arxiv.org/abs/1906.05856v1   \n",
       "14189  http://openaccess.thecvf.com/content_CVPR_2019...   \n",
       "14190                 https://arxiv.org/abs/1907.01227v1   \n",
       "14191                 https://arxiv.org/abs/1904.08352v2   \n",
       "14192                 https://arxiv.org/abs/1704.06616v2   \n",
       "14193                 https://arxiv.org/abs/1907.01627v1   \n",
       "14194                 https://arxiv.org/abs/1905.10748v2   \n",
       "14195                 https://arxiv.org/abs/1907.01743v1   \n",
       "\n",
       "                                           paper_url_pdf  \\\n",
       "0                 https://arxiv.org/pdf/1806.06098v1.pdf   \n",
       "1                 https://arxiv.org/pdf/1811.10582v2.pdf   \n",
       "2                 https://arxiv.org/pdf/1806.02988v1.pdf   \n",
       "3                 https://arxiv.org/pdf/1901.03035v1.pdf   \n",
       "4                 https://arxiv.org/pdf/1603.06127v4.pdf   \n",
       "5                 https://arxiv.org/pdf/1904.03371v1.pdf   \n",
       "6                 https://arxiv.org/pdf/1811.00866v1.pdf   \n",
       "7                 https://arxiv.org/pdf/1806.05645v1.pdf   \n",
       "8              https://www.aclweb.org/anthology/D18-1341   \n",
       "9                 https://arxiv.org/pdf/1904.02642v3.pdf   \n",
       "10                https://arxiv.org/pdf/1606.04414v4.pdf   \n",
       "11                https://arxiv.org/pdf/1805.12048v1.pdf   \n",
       "12                https://arxiv.org/pdf/1803.01299v2.pdf   \n",
       "13     http://papers.nips.cc/paper/5872-efficient-and...   \n",
       "14                https://arxiv.org/pdf/1805.10414v1.pdf   \n",
       "15                 https://arxiv.org/pdf/1206.2944v2.pdf   \n",
       "16                https://arxiv.org/pdf/1805.10799v1.pdf   \n",
       "17                 https://arxiv.org/pdf/1402.4102v2.pdf   \n",
       "18                https://arxiv.org/pdf/1806.06553v1.pdf   \n",
       "19                https://arxiv.org/pdf/1905.08942v2.pdf   \n",
       "20                https://arxiv.org/pdf/1803.08661v1.pdf   \n",
       "21                https://arxiv.org/pdf/1905.08786v2.pdf   \n",
       "22                https://arxiv.org/pdf/1802.07191v3.pdf   \n",
       "23                https://arxiv.org/pdf/1807.02811v1.pdf   \n",
       "24                https://arxiv.org/pdf/1602.01064v3.pdf   \n",
       "25                 https://arxiv.org/pdf/1402.0929v3.pdf   \n",
       "26                https://arxiv.org/pdf/1711.11511v5.pdf   \n",
       "27                https://arxiv.org/pdf/1704.04232v2.pdf   \n",
       "28                https://arxiv.org/pdf/1705.03854v3.pdf   \n",
       "29                https://arxiv.org/pdf/1806.01175v1.pdf   \n",
       "...                                                  ...   \n",
       "14166             https://arxiv.org/pdf/1802.07401v1.pdf   \n",
       "14167             https://arxiv.org/pdf/1804.07726v2.pdf   \n",
       "14168             https://arxiv.org/pdf/1906.09506v1.pdf   \n",
       "14169             https://arxiv.org/pdf/1804.06223v3.pdf   \n",
       "14170             https://arxiv.org/pdf/1907.00409v1.pdf   \n",
       "14171             https://arxiv.org/pdf/1907.00960v1.pdf   \n",
       "14172             https://arxiv.org/pdf/1905.03329v1.pdf   \n",
       "14173             https://arxiv.org/pdf/1906.08928v1.pdf   \n",
       "14174             https://arxiv.org/pdf/1908.01104v3.pdf   \n",
       "14175             https://arxiv.org/pdf/1906.09003v1.pdf   \n",
       "14176             https://arxiv.org/pdf/1906.01806v4.pdf   \n",
       "14177             https://arxiv.org/pdf/1804.06087v1.pdf   \n",
       "14178             https://arxiv.org/pdf/1906.11366v1.pdf   \n",
       "14179             https://arxiv.org/pdf/1905.06933v3.pdf   \n",
       "14180             https://arxiv.org/pdf/1906.11335v1.pdf   \n",
       "14181             https://arxiv.org/pdf/1611.10152v2.pdf   \n",
       "14182             https://arxiv.org/pdf/1902.06806v2.pdf   \n",
       "14183             https://arxiv.org/pdf/1907.01294v2.pdf   \n",
       "14184             https://arxiv.org/pdf/1801.00055v2.pdf   \n",
       "14185             https://arxiv.org/pdf/1901.03398v1.pdf   \n",
       "14186             https://arxiv.org/pdf/1907.01144v1.pdf   \n",
       "14187             https://arxiv.org/pdf/1907.01256v1.pdf   \n",
       "14188             https://arxiv.org/pdf/1906.05856v1.pdf   \n",
       "14189  http://openaccess.thecvf.com/content_CVPR_2019...   \n",
       "14190             https://arxiv.org/pdf/1907.01227v1.pdf   \n",
       "14191             https://arxiv.org/pdf/1904.08352v2.pdf   \n",
       "14192             https://arxiv.org/pdf/1704.06616v2.pdf   \n",
       "14193             https://arxiv.org/pdf/1907.01627v1.pdf   \n",
       "14194             https://arxiv.org/pdf/1905.10748v2.pdf   \n",
       "14195             https://arxiv.org/pdf/1907.01743v1.pdf   \n",
       "\n",
       "                                                repo_url          star_number  \\\n",
       "0           [https://github.com/google/tf_mesh_renderer]                [267]   \n",
       "1                  [https://github.com/necla-ml/SNLI-VE]                 [27]   \n",
       "2                [https://github.com/zhuohan123/g2-lstm]                 [56]   \n",
       "3      [https://github.com/chihyaoma/selfmonitoring-a...                 [73]   \n",
       "4                [https://github.com/brmson/dataset-sts]                [476]   \n",
       "5       [https://github.com/nouhadziri/DialogEntailment]                 [20]   \n",
       "6      [https://github.com/huanzhang12/CROWN-IBP, htt...  [16, 10, 10, 10, 8]   \n",
       "7         [https://github.com/claudiogreco/coling18-gte]                  [1]   \n",
       "8                   [https://github.com/trangvu/ape-npi]                  [1]   \n",
       "9              [https://github.com/boschresearch/MetaBO]                  [1]   \n",
       "10     [https://github.com/wujian16/qKG, https://gith...           [135, 135]   \n",
       "11        [https://github.com/mancinimassimiliano/caffe]                  [0]   \n",
       "12     [https://github.com/LiQianxiao/discrete-MSA, h...              [14, 0]   \n",
       "13              [https://github.com/automl/auto-sklearn]               [3752]   \n",
       "14                                                    []                   []   \n",
       "15     [https://github.com/JasperSnoek/spearmint, htt...      [1265, 1262, 0]   \n",
       "16     [https://github.com/hiddenmaze/InteractivePickup]                  [3]   \n",
       "17     [https://github.com/hsvgbkhgbv/TACTHMC, https:...            [4, 4, 0]   \n",
       "18                    [https://github.com/chang-li/SBOR]                  [0]   \n",
       "19           [https://github.com/HDI-Project/AutoBazaar]                  [5]   \n",
       "20     [https://github.com/toscanosaul/bayesian_quadr...                  [0]   \n",
       "21                   [https://github.com/ruizhaogit/mep]                  [5]   \n",
       "22              [https://github.com/kirthevasank/nasbot]                 [92]   \n",
       "23     [https://github.com/wujian16/qKG, https://gith...        [135, 135, 0]   \n",
       "24     [https://github.com/jmetzen/bayesian_optimizat...                 [17]   \n",
       "25                   [https://github.com/HIPS/Spearmint]               [1262]   \n",
       "26               [https://github.com/hsvgbkhgbv/TACTHMC]                  [4]   \n",
       "27     [https://github.com/zhengshou/AutoLoc, https:/...              [52, 4]   \n",
       "28                   [https://github.com/ndrplz/dreyeve]                 [56]   \n",
       "29        [https://github.com/lmb-freiburg/td-or-not-td]                  [7]   \n",
       "...                                                  ...                  ...   \n",
       "14166        [https://github.com/arjun23496/Shared-WGAN]                  [4]   \n",
       "14167         [https://github.com/ethonyLight/piqa_bert]                  [2]   \n",
       "14168  [https://github.com/DeepGraphLearning/Recommen...                [187]   \n",
       "14169  [https://github.com/scotthlee/autism_classific...                  [0]   \n",
       "14170   [https://github.com/jcblaisecruz02/Tagalog-BERT]                  [1]   \n",
       "14171  [https://github.com/erictuanle/GoingDeeperwPoi...                 [16]   \n",
       "14172  [https://github.com/gabsens/Learning-Embedding...                  [1]   \n",
       "14173         [https://github.com/malayandi/DemPrefCode]                  [0]   \n",
       "14174                 [https://github.com/liaohaofu/adn]                  [9]   \n",
       "14175        [https://github.com/c-hofer/COREL_icml2019]                  [2]   \n",
       "14176                 [https://github.com/liaohaofu/adn]                  [9]   \n",
       "14177                 [https://github.com/nginyc/rafiki]                 [16]   \n",
       "14178  [https://github.com/twistedcubic/que-outlier-d...                 [13]   \n",
       "14179        [https://github.com/woshiyyya/DFGN-pytorch]                 [55]   \n",
       "14180  [https://github.com/mdimiccoli/Nonlocal-self-s...                  [0]   \n",
       "14181  [https://github.com/HongwenZhang/ECT-FaceAlign...                 [22]   \n",
       "14182           [https://github.com/philadias/freelabel]                  [0]   \n",
       "14183  [https://github.com/fabvio/Cascade-LD, https:/...               [7, 4]   \n",
       "14184   [https://github.com/AliaksandrSiarohin/pose-gan]                [193]   \n",
       "14185                 [https://github.com/luizgh/sigver]                 [17]   \n",
       "14186                    [https://github.com/Honlan/DMT]                 [11]   \n",
       "14187          [https://github.com/kakaobrain/helo_word]                 [13]   \n",
       "14188      [https://github.com/PeterWang512/FALdetector]                [428]   \n",
       "14189    [https://github.com/gengshan-y/high-res-stereo]                 [31]   \n",
       "14190               [https://github.com/clovaai/TedEval]                 [73]   \n",
       "14191             [https://github.com/lochenchou/MOSNet]                 [11]   \n",
       "14192                    [https://github.com/h2r/GLAMDP]                  [1]   \n",
       "14193                    [https://github.com/paolo7/ap2]                  [0]   \n",
       "14194              [https://github.com/CuthbertCai/SRDA]                  [3]   \n",
       "14195                [https://github.com/wulalago/DAF3D]                 [14]   \n",
       "\n",
       "                                                    task  \n",
       "0                               [3d face reconstruction]  \n",
       "1      [natural language inference, question answerin...  \n",
       "2                                                     []  \n",
       "3      [natural language visual grounding, vision lan...  \n",
       "4      [natural language inference, reading comprehen...  \n",
       "5                                                     []  \n",
       "6                                                     []  \n",
       "7                           [natural language inference]  \n",
       "8          [automatic post editing, machine translation]  \n",
       "9                                        [meta learning]  \n",
       "10                                                    []  \n",
       "11            [domain adaptation, domain generalization]  \n",
       "12                                                    []  \n",
       "13                 [automl, hyperparameter optimization]  \n",
       "14                        [named entity recognition ner]  \n",
       "15                         [hyperparameter optimization]  \n",
       "16                                                    []  \n",
       "17                               [efficient exploration]  \n",
       "18                                [multi label learning]  \n",
       "19           [anomaly detection, automl, graph matching]  \n",
       "20                                                    []  \n",
       "21                   [multi goal reinforcement learning]  \n",
       "22     [bayesian optimisation, model selection, archi...  \n",
       "23                         [hyperparameter optimization]  \n",
       "24                                                    []  \n",
       "25                                                    []  \n",
       "26                                                    []  \n",
       "27     [action localization, object localization, wea...  \n",
       "28                                                    []  \n",
       "29                                                    []  \n",
       "...                                                  ...  \n",
       "14166                                                 []  \n",
       "14167        [question answering, reading comprehension]  \n",
       "14168  [knowledge graphs, policy gradient methods, re...  \n",
       "14169                          [document classification]  \n",
       "14170                               [language modelling]  \n",
       "14171                                                 []  \n",
       "14172                         [dimensionality reduction]  \n",
       "14173                                                 []  \n",
       "14174  [image to image translation, metal artifact re...  \n",
       "14175                          [representation learning]  \n",
       "14176  [image to image translation, metal artifact re...  \n",
       "14177  [automl, hyperparameter optimization, image cl...  \n",
       "14178                                [outlier detection]  \n",
       "14179                               [question answering]  \n",
       "14180                                                 []  \n",
       "14181                        [facial landmark detection]  \n",
       "14182                            [semantic segmentation]  \n",
       "14183              [autonomous vehicles, lane detection]  \n",
       "14184  [gesture to gesture translation, image generat...  \n",
       "14185                               [object recognition]  \n",
       "14186                           [facial makeup transfer]  \n",
       "14187  [grammatical error correction, transfer learning]  \n",
       "14188                     [image manipulation detection]  \n",
       "14189              [autonomous driving, stereo matching]  \n",
       "14190                             [scene text detection]  \n",
       "14191                                 [voice conversion]  \n",
       "14192                                                 []  \n",
       "14193                                                 []  \n",
       "14194  [domain adaptation, unsupervised domain adapta...  \n",
       "14195  [medical image segmentation, semantic segmenta...  \n",
       "\n",
       "[14196 rows x 8 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_json('../lastdata_ss_0816.json')\n",
    "df1 = df1.sort_index(ascending=False).drop_duplicates(\"title\")\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df4 = pd.read_json('../lastdata_pwc_with_paper_title_0816.json')\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['forks_count', 'latest_issues_created_at', 'latest_issues_updated_at',\n",
       "       'open_issues_count', 'readme_size', 'repo_created_at', 'repo_kept_time',\n",
       "       'repo_name', 'repo_size', 'repo_updated_at', 'repo_url_x',\n",
       "       'star_counts', 'subscribe_count', 'title', 'frame', 'paper_abstract',\n",
       "       'paper_url_abs', 'paper_url_pdf', 'repo_url_y', 'star_number', 'task',\n",
       "       'citations', 'img_num', 'img_src', 'meeting', 'pdf', 'topic', 'venue',\n",
       "       'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('../lastdata_git_api_std.json')\n",
    "df = df.sort_index(ascending=False).drop_duplicates(\"repo_url\")\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df3 = pd.read_json('../git_repo_paper_title.json')\n",
    "df3 = df3.sort_index(ascending=False).drop_duplicates(\"repo_url\")\n",
    "df3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df = pd.merge(df, df3, on='repo_url').drop_duplicates('paper_title').drop_duplicates('repo_url')\n",
    "df = pd.merge(df, df4, on='paper_title').drop_duplicates('paper_title')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df = df.rename(columns={'paper_title':'title'})\n",
    "df = pd.merge(df, df1, on=\"title\", how='inner')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可以加一个特征表示一个项目有多少个代码实现，值为frame加和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "achieve = []\n",
    "for i in range(len(df)):\n",
    "    achieve.append(len(df[\"frame\"][i]))\n",
    "df[\"achieve\"] = achieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再使用一个特征表示其使用的框架,$0-none,1-tf,3-pytorch,5-mxnet$如果有多种实现，就加和一下？\n",
    "# 比如$4:\\{tf,pytorch\\},6:\\{pytorch, mxnet\\},8:\\{pytorch, mxnet\\},9:\\{tf,pytorch, mxnet\\}$\n",
    "# 相同的框架只算一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\"tf\":1, \"torch\":3, \"mxnet\":5}\n",
    "frame_feature = []\n",
    "for i in range(len(df)):\n",
    "    if df[\"frame\"][i]:\n",
    "        value = 0\n",
    "        for j in df[\"frame\"][i]:\n",
    "            tmp = set()\n",
    "            tmp.add(j)\n",
    "            for frame in tmp:\n",
    "                value += dic[frame]\n",
    "        frame_feature.append(value)\n",
    "    else:\n",
    "        frame_feature.append(0)\n",
    "df[\"frame_feature\"] = frame_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[{'forks_count','star_counts','subscribe_count','open_issues_count','repo_kept_time','repo_size','citations','img_num','readme_size','achieve','frame_feature'}].copy()\n",
    "tmp = []\n",
    "for i in range(len(new_df)):\n",
    "    a = new_df[\"citations\"][i]\n",
    "    cite = 0\n",
    "    for j in a:\n",
    "        cite += int(j.replace(',',''))\n",
    "    tmp.append(cite)\n",
    "    #print(cite)\n",
    "    #if new_df[\"repo_kept_time\"][i] == '1 day, 0:00:00' or new_df[\"repo_kept_time\"][i] == '0:00:00':\n",
    "    new_df.loc[i, 'repo_kept_time'] = new_df.loc[i, 'repo_kept_time'].replace('1 day, 0:00:00', '1').replace('0:00:00', '1')\n",
    "new_df[\"cite_number\"] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.fillna(0)\n",
    "new_df = new_df.drop(columns='citations')\n",
    "data = pd.DataFrame(new_df,dtype=np.float)\n",
    "import numpy as np\n",
    "X = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[np.isnan()] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把$issues\\_count, star\\_count, forks\\_count$等都除以$repo\\_kept\\_time$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    X[i][3] /= X[i][5]\n",
    "    X[i][4] /= X[i][5]\n",
    "    X[i][7] /= X[i][5]\n",
    "    X[i][8] /= X[i][5]\n",
    "    X[i][9] /= X[i][5]\n",
    "    X[i][10] /= X[i][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#0099ff face=\"黑体\">Step 3：</font>PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X_2d = pca.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#0099ff face=\"黑体\">Step 3：</font>使用KMeans聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6588, 1: 1, 2: 1, 3: 69}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans # KMeans clustering \n",
    "import matplotlib.pyplot as plt\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "X_clustered = kmeans.fit_predict(X)\n",
    "dic1 = {0:0,1:0,2:0,3:0}\n",
    "for i in range(len(X_clustered)):\n",
    "    dic1[X_clustered[i]] += 1\n",
    "dic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "y_pred = DBSCAN(eps = 1e-100,min_samples = 10).fit_predict(X_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6659"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in y_pred:\n",
    "    if i == -1:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "#设置标题\n",
    "ax1.set_title('KMeans Clustering (PCA)')\n",
    "#设置X轴标签\n",
    "plt.xlabel('First Principal Component')\n",
    "#设置Y轴标签\n",
    "plt.ylabel('Second Principal Component')\n",
    "#plt.xlim(0, 2000000)\n",
    "#plt.ylim(0, 120000)\n",
    "#画散点图\n",
    "ax1.scatter(X_2d[:,0],X_2d[:,1],c = X_clustered, cmap='jet', marker = 'o')\n",
    "#显示所画的图\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
